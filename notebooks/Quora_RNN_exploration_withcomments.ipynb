{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "pal = sns.color_palette()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping the data which have NaN\n",
    "\n",
    "train.dropna(subset=['question1', 'question2', 'is_duplicate'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of positive example: 149263\n",
      "Number of negative example: 255025\n"
     ]
    }
   ],
   "source": [
    "# Identifying number of positive and negative examples in the training data set.\n",
    "\n",
    "train_pos = train[train['is_duplicate'] == 1]\n",
    "train_neg = train[train['is_duplicate'] == 0]\n",
    "print('Number of positive example:', len(train_pos))\n",
    "print('Number of negative example:', len(train_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 363859\n",
      "Test size: 40429\n",
      "(training : validation) =  9  : 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting training dataset into training and validation dataset, in ratio 9:1\n",
    "\n",
    "X_trainq1, X_validq1, X_trainq2, X_validq2, y_train, y_valid = train_test_split(train['question1'], train['question2'], train['is_duplicate'], test_size=0.1, random_state=1)\n",
    "\n",
    "print('Train size:', len(y_train))\n",
    "print('Test size:', len(y_valid))\n",
    "print('(training : validation) = ', round(len(y_train)/len(y_valid)),' : 1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91066"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "t = Tokenizer(num_words=25000)\n",
    "\n",
    "# fit the traing text using the tokenizer. \n",
    "t.fit_on_texts(X_trainq1.tolist() + X_trainq2.tolist())\n",
    "\n",
    "len(t.word_index)\n",
    "#print(t.word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> \n",
    "<font color='green'>print(t.word_index) prints something like this: each word is converted into a numerical\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p> \n",
    "<font color='blue'>{'the': 1, 'what': 2, 'is': 3, 'how': 4, 'i': 5, 'a': 6, 'to': 7, 'in': 8, 'do': 9, 'of': 10, 'are': 11, 'and': 12, 'can': 13, 'for': 14, 'you': 15, 'why': 16, 'my': 17, 'best': 18, 'it': 19, 'on': 20, 'does': 21, 'or': 22, 'which': 23, 'be': 24, 'if': 25, 'some': 26, 'have': 27, 'that': 28, 'with': 29, 'get': 30, 'should': 31, 'an': 32, 'from': 33, 'your': 34, 'india': 35, 'will': 36, 'when': 37, 'people': 38, 'who': 39, 'like': 40, 'at': 41, 'good': 42, 'would': 43, 'there': 44, 'as': 45, 'about': 46, 'not': 47, 'between': 48, 'one': 49, 'most': 50, 'we': 51, 'make': 52, 'quora': 53, 'way': 54, 'did': 55, 'where': 56, 'by': 57, 'any': 58, 'me': 59, 'was': 60, 'life': 61, 'so': 62, 'after': 63, 'time': 64, 'this': 65, 'they': 66, 'money': 67, 'know': 68, 'difference': 69, 'has': 70, 'learn': 71, 'am': 72, 'new': 73, \"what's\": 74, 'use': 75,\n",
    "</font>\n",
    "</p>\n",
    "\n",
    "<p> \n",
    "<font color='red'>Once fit, the Tokenizer provides 4 attributes that you can use to query what has been learned about your documents:\n",
    "<p>\n",
    "word_counts: A dictionary of words and their counts.\n",
    "</p>\n",
    "<p>\n",
    "word_docs: A dictionary of words and how many documents each appeared in.\n",
    "</p>\n",
    "<p>\n",
    "word_index: A dictionary of words and their uniquely assigned integers.\n",
    "</p>\n",
    "<p>\n",
    "document_count:An integer count of the total number of documents that were used to fit the Tokenizer.\n",
    "</p>\n",
    "</font>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The indicates, how many times each other appears for the data from training set.\n",
    "word_cnt = t.word_counts.values()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26783"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ignoring words with word_cnt <= 5\n",
    "np.count_nonzero(np.array(list(word_cnt)) > 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjun/venvs/tensorflow/lib/python3.5/site-packages/matplotlib/axes/_axes.py:6462: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Probability')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4AAAAJjCAYAAABdk3/PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzs3XuYJVV5L+Df5yCOiPGCqIRRQYNR\nwgSVEUEDGqMGxYjGSzCaAEnExGu8REz0KOoxUTFGPZIENCjmKGrUEFQUFUGIV4aIQUUUFWU4goB4\nQYOCrPNH1eCm6ZnpntndPTPrfZ9nP91VtXbVt3dV79m/WVWrqrUWAAAAtn43WeoCAAAAWBwCIAAA\nQCcEQAAAgE4IgAAAAJ0QAAEAADohAAIAAHRCAAS2alV1ZFW1qjpllmXvrarTl6CsjTK+jmdMTJ9e\nVe9dpG1fXlVHbqDNDepbR5tDx3bbz3G7dx/34a3nUe5Wr6oOqqrzqurnVXXhUtezLlW1/bi/D13q\nWgAYCIBALx5WVfdd6iKm7GlJ/nqpi5inDyXZN8lP59j+7klemkQAHFXVsiRvT/LFJA9O8pilrQiA\nLck2S10AwCL4fpKLk7woyaOnvfKqunlr7X+mvd4Naa19ZbG3ualaa5cluWyp61ifqqokN2utXb3U\ntazDTkl+Jck7W2v/udTFVNVNk1zXWvvFUteyEJbq7xtgoegBBHrQkrwyyaOqauX6GlbVvarq1Kr6\naVVdWVXvqKo7TCzfZTyl7UlV9faq+kGSD4zLLqyq11bVC6vqu1X1w6r6+xo8oqq+XFU/rqoTq+o2\nE+u8RVW9qarOH7f7rao6uqp+ZQO13uAU0KpaUVXvqarvVdX/VNU3quoVM56zX1V9ctzOFVX15qq6\n5Yw2+1fVF6vq6qo6u6ruP4f3eK1lVfW3VXXZWMfRVXWziXXf6BTQqvrrqrpg3N6lVfWRqrpjVT1o\n7Xub5Fvj8y6ceN5699XY5s5V9eHx/fjWuP0bnPo7nmJ6eVX9VlWdleTqJI+f634Z63rOuK+vGNf1\n/HHZIVX1zar6QVUdV1XLN/QGVtUTqurcqvpZVV1UVa+sqm3Wvn9JLhqb/se47SPXsZ5vV9XfTEw/\ndWz/rIl5z6uqiyemt6uqN1bVJeP+OKuqHjZjvaeP7+HhVfWN8f361XHZY6vqa+P7fUaSe2zo9Y7P\nu11VHT++fz8dt7FqlnZPGd+btcfKe6vqVhPL96+q06rqqhr+/k6vqnuPy46sqstnWefMU6svHPfl\n/6qqNUl+NLFsvX8/E8f3yqr6WFX9pKq+WlW/P8t2H1NVnx/fqyuq6uSqusvE8j2q6kM1fGb8uKr+\nraruOJf3E2B9BECgF/+W5OsZegFnVVU7Jjk9yXZJ/jDJM5M8MMnHqmrbGc1fm+THSR6f5G8n5h+c\nZO8khyV5TZLnJnldklck+V9J/nxc599NPGe7JMvG2h4+tnvwWPN8vD3JnZIcPq7nlUkmw9cDknw8\nySVJHpfkL5M8IslbJ9r8apIPZ+g1fVySY5K8Y6xxLp6XIQw8OclRSZ6a5NnralxVf5zkbzK8R7+b\n5C+SXJDkFkn+K8nzx6a/n+HU0ceMz9vgvqqqSnJSknsm+ZMM++JZSe43SynbJTk+yVuSHJDk85nf\nfnleku2TPDHJO5McVVWvSXLouM2/SfKkDO/5Oo1h693jaz8oyf8Z34M3jU0+NL4XGefvO9Y8mzOT\n7DcxvX+GsDZz3pkT02/OcOy+MsN7fVGSD1XVb81Y9wMy7Ksjkvxekh9W1X3G2r841viBJO9Z3+ud\ncGKG/f/8JH+Q4fvJaVX1a2sbVNWLMxyPn8zQk/8XSX6Y4X1PDf9hcGqSa5IcMq7nzCQ7z7GGSX+Y\n4Xh62rieOf39THhnhmPvMRk+d95VVSsmXssfJXl/km8keUKG9/xrSXYcl/9akk8lWZ7hb+nQJL+R\n5APjcQ2w8VprHh4eHlvtI8mRSS4ffz80yS+S3H2cfm+S0yfavirJD5L8ysS8+2XoQXziOL3LOP3v\ns2zrwgzhZdnEvM8nuTbJrhPzXpPk0vXUvE2GL9gtyZ0n5rckz5iYPj3Jeyemr0rye+tZ75lJTpsx\n78HjeveYqO2KJNtNtHnS2ObIDbzXLckZM+admOSzE9OHju22H6fflOR961nnI8f2u8yYP5d9deA4\nfd+JNjtnCAiT+/3Isd1BG3h969svp01M3yTJd5NcOaO+9yT53Aa28dlZ9tELxuN2xYxj8JEbWNdT\nMwSkm4zT3xnf70vG6Rr39dPH6XsmuS7JITNey5eSnDLjuPufJHeYsb33JPlKkpqY96Kx1kPXU+cB\nY5sHTsy7RYZThY8Zp2+d4brR161nPZ9Jsnpy+zOWH5nxs2CW43by7+rCcf8t34i/n0PH6T+ZaLND\nhs+AP594Ty9O8v71vJZ/TXJ+km0n5u02HgcHrm+/e3h4eGzooQcQ6Mn/zfAleF0Dp+yd5KOttetP\n+WqtfS7DF8KZPSAfWsc6Tm83vBbqgiQXtta+NWPejpO9ilX1R1X1haq6KkNAWXtt193X/5Ju4Jwk\nfzeehnbnyQVVtV2G3qL3VNU2ax/jdq5JstfYdO8kH2utTQ7S8u/zqOGjM6a/kmTFbA0nan5EVb2s\nqvauYYCTuZjLvrpvhrBz1kSbi5OcPcv6WoaezxuYx345dWIb1yX5VpKzJ+vLsN/X2Rs1vvb75MY9\njO/OEBr2Xddz1+GMDNcK7llVu2TYD69Jcruq2i1Dj9Jt88sewPtmCIXXb398Lf+WGx//Z7fWLp0x\nb+8kJ7XW2sS898+hzr2TfK+19smJ7f4kyQcntrtvkptn9t62VNUtMvwHwPEztr+xTm0T14DO4+9n\nrev/DlprVyT5Xn75d/DrGXrJZ30to4dk+Lu7bmJb38pwfN/o1FiA+RAAgW601q7N8AX4yZPX2kzY\nKcnML7UZ5912lnmz+cGM6Z+vY14lWXuq4mMynL75mQynlO6TX47suMFrxib8QYYekH9I8u2qOqeq\nfmdcdpsMpzP+Y4YvrGsfP0ty0wynjibJHTN8Wb3eGAavmmMNs73W9b2G4zKcHvmEJJ9LcmlV/e85\nBMG57Ks7ZvYBZ2abd2Vr7eeTM+a5X+a639f3Xtwuw76Y+brWTs88Bjfkq0kuz3DK535JvtRa+06G\n0L123g8y9PAlw3t61Yzwv3b729XEtZyz1JjMcuzMMj2bndbRbnJf7jD+/O461nGbDH9T61o+XzNf\n31z/ftZa377f0GtJhmPhiBnbuibJXWfZFsC8GAUU6M1xSV6c4cvVTN9NcvtZ5t8hN+41mkYvw1qP\nz3Bq4NPWzqiqB853JWPv1qFVdZMMvSpHJjlp7A38QcbTOJOcPMvT/9/485LMeA/G3o853bdvI2q+\nLkNg/YequlOG001fmWRNkn9ez1Pnsq8uyXhN1Qw7ZrgW7galzNJuKvtlHi7P8CV/5utaO7DN9+ez\nstZaq6r/zC+D3hnjorXXBi5P8qlxHyTDe7p9VW03IwTeIclPW2s/m1z9LJu80bEzy/Rs1rcv177m\nK8afO2V4n2a6MsPpqzutZztXZ/xPl7VqYjCmGWa+vrn+/czF5GtZl+9n6AGc7frO2V4/wJzpAQS6\nMn6JfW2GQUFmfgH7XJLfnTGq330zXHO1kMPt3zxDT8KkJ23sylpr17XWPpvkZRkGMrnLeErdZ5P8\nemtt9SyPtV9gz0ry0DH0rbUo95lrrV3UWntVhlMldx9nr+2Vm9lzNpd9dVaSO1bV3hNtds6NT9db\nl6nulw0ZTx0+O0PwnPSEDOHmMxux2jMyhL3988sAuHbefrnhADBnZQg5j1s7Yxxw5HGZ2/F/VoaR\ndicHKbnR6Jez+FyS21fV/hPb3S7DNZxrt/uZDNcdHjLbCsbj+3NJ/ng9g6SsSXLL8RhY62HraDvb\n+ufy9zMX52e4BnDW1zI6NcMpumfPsq0L57EtgBvRAwj06JgMpx3eP8OIgmu9LsPIgqdU1asz9Hq9\nKsm5Sd63gPV8LMnRVfWiDF9iH5Hkd9b/lBsah8I/JcMpi1/LMPrn8zL0ypw3NntBklOr6roMA+D8\nOMmdM3zRflFr7WtJXp/k6Uk+WFWvy3Ct0l9n+PI9dVV1TIbejs9mGLDktzMMdrG2h/b88edTq+pd\nGXqizs3c9tXJGUakfE9VrX0NL81wet/aXq/12eT9shFemuE1vTXJu5KszDCC7Jtba2s2Yn1nZniv\n7pBfBsD/THK3ieVJktbaeVV1QpI3jcH6G0mekuFWDn8xh229OsP79J6q+pckeyT50w09qbV2SlV9\nOsm7q+qFGXrInp8hgB81tvlBDbc0eeV47ezJGY7xA5O8bOz9fmGGUTo/XFXHJvlJhuv2VrfWPpjk\nIxmOgeOq6u+T7JphVN65msvfzwa11q6rqhckeUdVvSPJCRmC94OTnNBaW52hp/HzGUZgPS5Dr9/O\nSR6a5G2ttdPnUTfADegBBLoznt72D7PMvyxDALk6w5eyozN8QX7ozOvDpuyYJH+f4XYJ709ylwzD\n0M/H1RnCz7MzDD9/fIZREx/WxptYt+Gm4ftnOAXyXzMM0/+CDEP9Xzq2uThD0LldhiD1tAzD0M+8\nLmxaPjPW9NYMX+ofk+QprbUTx3q+nSEM/H6GYfE/MM7f4L4aBwM5KMO1cG9N8oYk/5RhYJrJwVnW\nZRr7ZV5aax/NcCuRVRle61+ONTxjfc9bjy9kuH7z6621S8ZtXJbhPbk6wzWjk56S4dh5SZL/yPCa\nH9nmcMP5MbgcnOTeGUZ/fXTGWyjMwaMzBO7XZxh0ppI8uLV2wcT6/y5DEH3IWNsxGUYH/fG4/IwM\nAWm7DAM+vTvDrRzWjMsvT/LYDIOxnJjhuJ7z/pzL38881vXOsZZ7ZAiTbx9/v2xc/rUM15z+NMmx\nGQYoelmGHukLZlklwJzVdAbLAoDN39hT+s0kb2qtvXSp6wGAxeYUUAC2WlX15xlO9/x6hp6b52Y4\ndfC4pawLAJaKAAjA1uzqDNcT3iXDdVafT/KQ8dRSAOiOU0ABAAA6YRAYAACATmwVp4De7na3a7vs\nsstSlwEAALAkzj777MtbaztuqN1WEQB32WWXrF49cyRrAACAPlTVnK5vdwooAABAJwRAAACATgiA\nAAAAndgqrgEEAAC2DNdcc03WrFmTq6++eqlL2SItX748K1asyE1vetONer4ACAAALJo1a9bklre8\nZXbZZZdU1VKXs0VpreWKK67ImjVrsuuuu27UOpwCCgAALJqrr746O+ywg/C3EaoqO+ywwyb1ngqA\nAADAohL+Nt6mvncCIAAAQCdcAwgAACyZlcevnOr6zj3k3Kmub2ujBxAAAGATnH766XnkIx85tfWd\neOKJ+cpXvjK19U0SAAEAAObhF7/4xYKuXwAEAACYgqOOOipvfOMbkyTPec5z8uAHPzhJ8olPfCJP\netKTcsIJJ2TlypXZY489csQRR1z/vO233z7Pe97zsueee+Yzn/lMPvKRj+Qe97hH7nOf++T973//\nerd51VVX5bDDDsvKlSvzm7/5m3nf+953/Tpf9KIXZc8998w+++yTSy+9NJ/+9Kdz0kkn5a/+6q9y\nr3vdK9/4xjem+voFQAAAoBv77bdfzjzzzCTJ6tWrc9VVV+Waa67JmWeembvf/e454ogj8olPfCLn\nnHNOzjrrrJx44olJkp/85Ce53/3uly9+8YtZtWpVnvKUp+QDH/hAzj777FxyySXr3eYrXvGK3OpW\nt8q5556b//7v/74+dP7kJz/JPvvsky9+8YvZf//98+Y3vzn3v//986hHPSpHHXVUzjnnnNztbneb\n6usXAAEAgG7stddeOfvss/OjH/0oN7vZzbLvvvtm9erVOfPMM3PrW986D3rQg7Ljjjtmm222yZOe\n9KScccYZSZJly5blsY99bJLkq1/9anbdddfstttuqao8+clPXu82P/7xj+fpT3/69dO3uc1tkiTb\nbrvt9dcO7rXXXrnwwgsX4BXfkAAIAAB046Y3vWl23XXXvO1tb8v973//7LfffjnttNNywQUXZJdd\ndlnn85YvX55ly5ZNvZa19/VbtmxZrr322qmufzZuAwEAACyZpbhtw3777ZfXvva1Oe6447Jy5co8\n97nPzV577ZW99947z3rWs3L55ZfnNre5TU444YQ885nPvNHz73GPe+TCCy/MN77xjdztbnfLCSec\nsN7tPfShD83RRx+d17/+9UmSK6+88vpewNnc8pa3zI9//ONNe5HroAcQAADoyn777Zfvfve72Xff\nfXOHO9why5cvz3777Zeddtopr3rVq/Lbv/3b2XPPPbPXXnvloIMOutHzly9fnmOPPTYHHnhg7nOf\n++T2t7/9erf34he/OFdeeWX22GOP7LnnnjnttNPW2/7ggw/OUUcdlXvf+95THwSmWmtTXeFSWLVq\nVVu9evVSlwEAAGzAeeedl3ve855LXcYWbbb3sKrObq2t2tBz9QACAAB0wjWAAAAAU/DWt741b3jD\nG24w7wEPeECOPvroJaroxgRAAABgUbXWrh/9cmty2GGH5bDDDlvQbWzqJXxOAQUAABbN8uXLc8UV\nV2xykOlRay1XXHFFli9fvtHr0AMIAAAsmhUrVmTNmjW57LLLlrqULdLy5cuzYsWKjX6+AAgAACya\ntTdiZ2kIgEto5fEr17lsKW6ICQAAbN1cAwgAANAJARAAAKATAiAAAEAnBEAAAIBOCIAAAACdEAAB\nAAA6IQACAAB0QgAEAADohAAIAADQCQEQAACgEwIgAABAJwRAAACATgiAAAAAnRAAAQAAOiEAAgAA\ndEIABAAA6IQACAAA0AkBEAAAoBMCIAAAQCcEQAAAgE4IgAAAAJ0QAAEAADohAAIAAHRCAAQAAOiE\nAAgAANAJARAAAKATAiAAAEAnBEAAAIBOCIAAAACdEAABAAA6IQACAAB0QgAEAADohAAIAADQCQEQ\nAACgEwIgAABAJwRAAACATgiAAAAAnRAAAQAAOiEAAgAAdEIABAAA6IQACAAA0AkBEAAAoBMCIAAA\nQCcEQAAAgE4IgAAAAJ0QAAEAADohAAIAAHRi0QNgVR1QVedX1QVV9cL1tHtsVbWqWrWY9QEAAGyt\nFjUAVtWyJEcneXiS3ZM8sap2n6XdLZM8O8nnFrM+AACArdli9wDuneSC1to3W2s/T/KuJAfN0u4V\nSV6d5OrFLA4AAGBrttgBcOckF01MrxnnXa+q7pPkTq21D61vRVV1eFWtrqrVl1122fQrBQAA2Mps\nVoPAVNVNkrwuyfM21La1dmxrbVVrbdWOO+648MUBAABs4RY7AF6c5E4T0yvGeWvdMskeSU6vqguT\n7JPkJAPBAAAAbLrFDoBnJdmtqnatqm2THJzkpLULW2s/bK3drrW2S2ttlySfTfKo1trqRa4TAABg\nq7OoAbC1dm2SZyQ5Jcl5Sd7TWvtyVb28qh61mLUAAAD0ZpvF3mBr7eQkJ8+Y95J1tH3QYtQEAADQ\ng81qEBgAAAAWjgAIAADQCQEQAACgEwIgAABAJwRAAACATgiAAAAAnRAAAQAAOiEAAgAAdEIABAAA\n6IQACAAA0AkBEAAAoBMCIAAAQCcEQAAAgE4IgAAAAJ0QAAEAADohAAIAAHRCAAQAAOiEAAgAANAJ\nARAAAKATAiAAAEAnBEAAAIBOCIAAAACdEAABAAA6IQACAAB0QgAEAADohAAIAADQCQEQAACgEwIg\nAABAJwRAAACATgiAAAAAnRAAAQAAOiEAAgAAdEIABAAA6IQACAAA0AkBEAAAoBMCIAAAQCcEQAAA\ngE4IgAAAAJ0QAAEAADohAAIAAHRCAAQAAOiEAAgAANAJARAAAKATAiAAAEAnBEAAAIBOCIAAAACd\nEAABAAA6IQACAAB0QgAEAADohAAIAADQCQEQAACgEwIgAABAJwRAAACATgiAAAAAnRAAAQAAOiEA\nAgAAdEIABAAA6IQACAAA0AkBEAAAoBMCIAAAQCcEQAAAgE4IgAAAAJ0QAAEAADohAAIAAHRCAAQA\nAOiEAAgAANAJARAAAKATAiAAAEAnBEAAAIBOCIAAAACdEAABAAA6IQACAAB0QgAEAADohAAIAADQ\nCQEQAACgEwIgAABAJwRAAACATgiAAAAAnRAAAQAAOiEAAgAAdEIABAAA6IQACAAA0AkBEAAAoBMC\nIAAAQCcEQAAAgE4IgAAAAJ0QAAEAADohAAIAAHRCAAQAAOiEAAgAANAJARAAAKATAiAAAEAnBEAA\nAIBOCIAAAACdEAABAAA6IQACAAB0QgAEAADohAAIAADQCQEQAACgEwIgAABAJwRAAACATgiAAAAA\nnRAAAQAAOiEAAgAAdEIABAAA6IQACAAA0AkBEAAAoBMCIAAAQCcWPQBW1QFVdX5VXVBVL5xl+Z9X\n1blVdU5V/WdV7b7YNQIAAGyNFjUAVtWyJEcneXiS3ZM8cZaA987W2srW2r2SvCbJ6xazRgAAgK3V\nYvcA7p3kgtbaN1trP0/yriQHTTZorf1oYvIWSdoi1gcAALDV2maRt7dzkosmptckud/MRlX19CTP\nTbJtkgfPtqKqOjzJ4Uly5zvfeeqFAgAAbG02y0FgWmtHt9buluSIJC9eR5tjW2urWmurdtxxx8Ut\nEAAAYAu02AHw4iR3mpheMc5bl3clefSCVgQAANCJxQ6AZyXZrap2raptkxyc5KTJBlW128TkgUm+\nvoj1AQAAbLUW9RrA1tq1VfWMJKckWZbkuNbal6vq5UlWt9ZOSvKMqnpIkmuSXJnkkMWsEQAAYGu1\n2IPApLV2cpKTZ8x7ycTvz17smgAAAHqwWQ4CAwAAwPQJgAAAAJ0QAAEAADohAAIAAHRCAAQAAOiE\nAAgAANAJARAAAKATAiAAAEAnBEAAAIBOCIAAAACdEAABAAA6IQACAAB0QgAEAADohAAIAADQCQEQ\nAACgEwIgAABAJwRAAACATgiAAAAAnRAAAQAAOiEAAgAAdEIABAAA6IQACAAA0AkBEAAAoBMCIAAA\nQCcEQAAAgE4IgAAAAJ0QAAEAADohAAIAAHRCAAQAAOiEAAgAANAJARAAAKATAiAAAEAnBEAAAIBO\nCIAAAACdEAABAAA6Ma8AWFXLFqoQAAAAFtZ8ewAvrqrXVNU9F6QaAAAAFsx8A+A/J3lcki9V1eeq\n6vCq+pUFqAsAAIApm1cAbK0d2Vq7a5KHJjk/yeuSfLeq3lFVD1mIAgEAAJiOjRoEprX2idbaHye5\nY5JnJvn1JKdU1YVVdWRV/eo0iwQAAGDTbeoooKuS7J/kHkmuTHJmkj9LckFVPXkT1w0AAMAUzTsA\nVtVdquqlVfWNJKcm2SnJnyT51dbaHyW5S5Jjkhw11UoBAADYJNvMp3FVnZZkvyQXJ3lrkre21r49\n2aa19ouqemeSZ0+tSgAAADbZvAJgku8leUSSj7XW2nranZNk142uCgAAgKmb7ymgRyf59Gzhr6q2\nr6r9k6S1ds3MnkEAAACW1nwD4GlJdl/Hsl8flwMAALAZmm8ArPUs2z7JTzehFgAAABbQBq8BHE/r\nfNDErD+rqgNmNFue5MAk506vNAAAAKZpLoPA3C/Dzd6TpCV5fJJrZ7T5eZKvJvmr6ZUGAADANG0w\nALbWjsp4T7+q+laSx7TWzlnowgAAAJiued0GorXm1g4AAABbqLlcA/iIJP/ZWvvR+Pt6tdZOnkpl\nAAAATNVcegA/mGSfJJ8ff29Z92igLcmy6ZQGAADANM0lAO6a5LsTvwMAALAFmssgMN+e7XcAAAC2\nLHO5BnC7+aywteZm8AAAAJuhuZwCelWGa/vmyjWAAAAAm6G5BMA/yfwCIAAAAJuhuVwD+LZFqAMA\nAIAFdpOlLgAAAIDFMZdBYD6f5NDW2leq6qxs4HTQ1tre0yoOAACA6ZnLNYBfTvI/E7+7HhAAAGAL\nNJdrAA+b+P3QBa0GAACABbPR1wDWYMeqqmkWBAAAwMKYdwCsqkdU1aeTXJ3kkiRXV9Wnq+rAqVcH\nAADA1MwrAFbVU5N8IMPN4Z+d5PHjz6uSnDQuBwAAYDM0l0FgJv1NkmNaa0+bMf+fq+qfk7woyTFT\nqQwAAICpmu8poDsk+fd1LHtfkttuWjkAAAAslPkGwNOSPHAdyx6Y5IxNKwcAAICFMpcbwe8+MfnG\nJG+pqh2SnJjke0lun+QxSR6e5M8WokgAAAA23VyuAfxSbnjz90ry1PHRxum1PpJk2dSqAwAAYGrm\nEgB/e8GrAAAAYMFtMAC21j65GIUAAACwsOZ7G4jrVdVNkiyfOb+19tNNqggAAIAFMd8bwVdVHVFV\nFyS5JsmPZ3kAAACwGZrvbSCeleSFSf4lw+Avr0zy8iRfS3JhksOnWRwAAADTM98A+JQkL03ymnH6\nxNbay5L8RpKvJtltirUBAAAwRfMNgLsmOae19osMp4DeOklaa9cl+cckh0y3PAAAAKZlvgHwiiTb\nj79/J8m9J5bdJsnNp1EUAAAA0zffUUA/leS+SU5O8s4kR1bVbZP8PMnTk5w63fIAAACYlvkGwCOT\n7Dz+/rcZTgE9NEPP38eSPHNahQEAADBd8wqArbXzk5w//v6zJM8eHwAAAGzmNuVG8CuS7JTk/7XW\nLp5eSQAAACyE+Q4Ck6r6i6q6KMm3k3wuyXeqak1VPW3q1QEAADA18wqAVfWSJG9K8uEkByZZNf78\ncJI3jssBAADYDM33FNCnJ/nb1tr/mjH/I1V16bj85VOpDAAAgKma7ymgN09yxjqWfTLJ8k0rBwAA\ngIUy3wB4YpLfX8eyxyb54KaVAwAAwELZ4CmgVfWIickPJ3lNVe2SIQx+L8ntkzwmyW8kecH0SwQA\nAGAa5nIN4AeTtCQ1MW/nJL87S9v/m+SEKdQFAADAlM0lAO664FUAAACw4DYYAFtr316MQgAAAFhY\n870NRKpqmwwDvvxWktsm+X6SM5O8v7V27XTLAwAAYFrmFQCr6vZJPprkN5NcmOTSJPtmuP/fF6vq\nYa21y6ZdJAAAAJtuvreBeF2SHZLs01q7a2tt39baXZPcb5z/umkXCAAAwHTMNwA+IskRrbXPT85s\nrZ2V5K+THDitwgAAAJiu+QbG0mvsAAAUeUlEQVTAmyX58TqW/TjJtptWDgAAAAtlvgHws0mOqKpb\nTM4cp48YlwMAALAZmu8ooM9LclqSi6rqoxkGgbl9hpvCV5IHTbU6AAAApmZePYCttXOS7Jbk2CQ7\nJnlohgD4z0l2a619ceoVAgAAMBVz7gGsqpsm2TvJt1prL1y4kgAAAFgI8+kB/EWSTyS5xwLVAgAA\nwAKacwBsrV2X5OtJ7rhw5QAAALBQ5jsK6IuSvKSqVi5EMQAAACyc+Y4C+uIkOyQ5p6ouzjAKaJts\n0Frbe0q1AQAAMEXzDYBfGh8AAABsYeYUAKvq5kkekSH8XZLk4621SxeyMAAAAKZrgwGwqu6a5ONJ\ndpmY/aOqekJr7aMLVRgAAADTNZdBYF6T5Lok+yXZLslvJPlCkmM2ZoNVdUBVnV9VF1TVje4nWFXP\nraqvVNV/V9WpVXWXjdkOAAAANzSXALhvkhe31j7VWru6tXZekqcmuXNV7TSfjVXVsiRHJ3l4kt2T\nPLGqdp/R7AtJVrXWfjPJezMEUAAAADbRXALgTkm+OWPeN5JU5n9PwL2TXNBa+2Zr7edJ3pXkoMkG\nrbXTWms/HSc/m2TFPLcBAADALOZ6H8C24SZzsnOSiyam14zz1uVPk3x4tgVVdXhVra6q1ZdddtmU\nygMAANh6zfU2EKdU1bWzzD915vzW2u03vaykqp6cZFWSB862vLV2bJJjk2TVqlXTCqgAAABbrbkE\nwJdNcXsXJ7nTxPSKcd4NVNVDkrwoyQNbaz+b4vYBAAC6tcEA2FqbZgA8K8luVbVrhuB3cJI/nGxQ\nVffOMMLoAa21701x2wAAAF2b6zWAU9FauzbJM5KckuS8JO9prX25ql5eVY8amx2VZPsk/1ZV51TV\nSYtZIwAAwNZqrtcATk1r7eQkJ8+Y95KJ3x+y2DUBAAD0YFF7AAEAAFg6AiAAAEAnBEAAAIBOCIAA\nAACdEAABAAA6IQACAAB0QgAEAADohAAIAADQCQEQAACgEwIgAABAJwRAAACATgiAAAAAnRAAAQAA\nOiEAAgAAdEIABAAA6IQACAAA0AkBEAAAoBMCIAAAQCcEQAAAgE4IgAAAAJ0QAAEAADohAAIAAHRC\nAAQAAOiEAAgAANAJARAAAKATAiAAAEAnBEAAAIBOCIAAAACdEAABAAA6IQACAAB0QgAEAADohAAI\nAADQCQEQAACgEwIgAABAJwRAAACATgiAAAAAnRAAAQAAOiEAAgAAdEIABAAA6IQACAAA0AkBEAAA\noBMCIAAAQCcEQAAAgE4IgAAAAJ0QAAEAADohAAIAAHRCAAQAAOiEAAgAANAJARAAAKATAiAAAEAn\nBEAAAIBOCIAAAACd2GapC2B2K49fud7l5x5y7iJVAgAAbC30AAIAAHRCAAQAAOiEAAgAANAJARAA\nAKATAiAAAEAnBEAAAIBOCIAAAACdEAABAAA6IQACAAB0QgAEAADohAAIAADQCQEQAACgEwIgAABA\nJwRAAACATgiAAAAAnRAAAQAAOiEAAgAAdEIABAAA6IQACAAA0AkBEAAAoBMCIAAAQCcEQAAAgE4I\ngAAAAJ0QAAEAADohAAIAAHRCAAQAAOiEAAgAANAJARAAAKATAiAAAEAnBEAAAIBOCIAAAACdEAAB\nAAA6IQACAAB0QgAEAADohAAIAADQCQEQAACgEwIgAABAJwRAAACATgiAAAAAnRAAAQAAOiEAAgAA\ndEIABAAA6IQACAAA0AkBEAAAoBMCIAAAQCcEQAAAgE4IgAAAAJ0QAAEAADohAAIAAHRCAAQAAOiE\nAAgAANAJARAAAKATAiAAAEAnBEAAAIBOLHoArKoDqur8qrqgql44y/L9q+q/quraqnrcYtcHAACw\ntVrUAFhVy5IcneThSXZP8sSq2n1Gs+8kOTTJOxezNgAAgK3dNou8vb2TXNBa+2aSVNW7khyU5Ctr\nG7TWLhyXXbfItQEAAGzVFvsU0J2TXDQxvWacN29VdXhVra6q1ZdddtlUigMAANiabbGDwLTWjm2t\nrWqtrdpxxx2XuhwAAIDN3mIHwIuT3GliesU4DwAAgAW22AHwrCS7VdWuVbVtkoOTnLTINQAAAHRp\nUQNga+3aJM9IckqS85K8p7X25ap6eVU9Kkmq6r5VtSbJ45McU1VfXswaAQAAtlaLPQpoWmsnJzl5\nxryXTPx+VoZTQwEAAJiiLXYQGAAAAOZHAAQAAOiEAAgAANAJARAAAKATAiAAAEAnBEAAAIBOCIAA\nAACdEAABAAA6IQACAAB0QgAEAADohAAIAADQCQEQAACgEwIgAABAJwRAAACATgiAAAAAnRAAAQAA\nOiEAAgAAdEIABAAA6IQACAAA0AkBEAAAoBMCIAAAQCcEQAAAgE4IgAAAAJ0QAAEAADohAAIAAHRi\nm6UugI2z8viV611+7iHnLlIlAADAlkIPIAAAQCcEQAAAgE4IgAAAAJ0QAAEAADohAAIAAHRCAAQA\nAOiEAAgAANAJARAAAKATAiAAAEAnBEAAAIBOCIAAAACdEAABAAA6IQACAAB0QgAEAADohAAIAADQ\nCQEQAACgEwIgAABAJwRAAACATgiAAAAAnRAAAQAAOiEAAgAAdEIABAAA6IQACAAA0AkBEAAAoBMC\nIAAAQCcEQAAAgE4IgAAAAJ0QAAEAADohAAIAAHRim6UugIWx8viV61x27iHnLmIlAADA5kIPIAAA\nQCcEQAAAgE4IgAAAAJ0QAAEAADohAAIAAHRCAAQAAOiEAAgAANAJARAAAKATAiAAAEAnBEAAAIBO\nCIAAAACdEAABAAA6IQACAAB0QgAEAADohAAIAADQCQEQAACgE9ssdQEsvpXHr1zv8nMPOXeRKgEA\nABaTHkAAAIBOCIAAAACdEAABAAA6IQACAAB0QgAEAADohAAIAADQCQEQAACgE+4DyI2s7z6B7hEI\nAABbLj2AAAAAnRAAAQAAOiEAAgAAdEIABAAA6IQACAAA0AkBEAAAoBNuA8G8rO8WEYnbRAAAwOZM\nDyAAAEAnBEAAAIBOCIAAAACdEAABAAA6YRAYpsogMQAAsPnSAwgAANAJARAAAKATTgFlUa3vFFGn\nhwIAwMLSAwgAANAJARAAAKATTgFls2EEUQAAWFgCIFsM1w8CAMCmEQDZKug9BACADRMA6YKACAAA\nBoEBAADohh5AyIZ7CNdH7yEAAFsKARA2kfAIAMCWQgCEJSQ8AgCwmARA2EJtSnhM1h8gDZoDALB1\nEgChU5sSIDc1fG4swRMAYNMsegCsqgOSvCHJsiRvaa29asbymyV5e5K9klyR5A9aaxcudp3A5mep\ngudC2lCo1RsLAEzTogbAqlqW5OgkD02yJslZVXVSa+0rE83+NMmVrbVfq6qDk7w6yR8sZp0Ai2VT\nQ+3WGIqXykKG6YUM8v6TAID5WOwewL2TXNBa+2aSVNW7khyUZDIAHpTkyPH39yZ5U1VVa60tZqEA\n9GUpw/RCbtt/EgBM15b+H2uLHQB3TnLRxPSaJPdbV5vW2rVV9cMkOyS5fLJRVR2e5PBx8qqqOn9B\nKt40t8uMumGKHF8sJMcXC80xxkJyfLFg6tDaXI+vu8yl0RY7CExr7dgkxy51HetTVatba6uWug62\nTo4vFpLji4XmGGMhOb5YSFv68XWTRd7exUnuNDG9Ypw3a5uq2ibJrTIMBgMAAMAmWOwAeFaS3apq\n16raNsnBSU6a0eakJIeMvz8uySdc/wcAALDpFvUU0PGavmckOSXDbSCOa619uapenmR1a+2kJP+S\n5F+r6oIk388QErdUm/UpqmzxHF8sJMcXC80xxkJyfLGQtujjq3SuAQAA9GGxTwEFAABgiQiAAAAA\nnRAAF0hVHVBV51fVBVX1wqWuhy1bVd2pqk6rqq9U1Zer6tnj/NtW1ceq6uvjz9ssda1suapqWVV9\noao+OE7vWlWfGz/H3j0O3gXzVlW3rqr3VtVXq+q8qtrX5xfTUlXPGf9t/FJVnVBVy31+sSmq6riq\n+l5VfWli3qyfWTV443is/XdV3WfpKp8bAXABVNWyJEcneXiS3ZM8sap2X9qq2MJdm+R5rbXdk+yT\n5OnjMfXCJKe21nZLcuo4DRvr2UnOm5h+dZJ/aK39WpIrk/zpklTF1uANST7SWrtHkj0zHGc+v9hk\nVbVzkmclWdVa2yPDIIMHx+cXm+ZtSQ6YMW9dn1kPT7Lb+Dg8yT8tUo0bTQBcGHsnuaC19s3W2s+T\nvCvJQUtcE1uw1tp3W2v/Nf7+4wxfnnbOcFwdPzY7Psmjl6ZCtnRVtSLJgUneMk5Xkgcnee/YxPHF\nRqmqWyXZP8Mo32mt/by19oP4/GJ6tkly8/H+0dsl+W58frEJWmtnZLgbwaR1fWYdlOTtbfDZJLeu\nqp0Wp9KNIwAujJ2TXDQxvWacB5usqnZJcu8kn0tyh9bad8dFlyS5wxKVxZbv9UlekOS6cXqHJD9o\nrV07TvscY2PtmuSyJG8dTzF+S1XdIj6/mILW2sVJXpvkOxmC3w+TnB2fX0zfuj6ztrjv/QIgbEGq\navsk70vyl621H00ua8M9XdzXhXmrqkcm+V5r7eylroWt0jZJ7pPkn1pr907yk8w43dPnFxtrvA7r\noAz/0fCrSW6RG5+6B1O1pX9mCYAL4+Ikd5qYXjHOg41WVTfNEP7e0Vp7/zj70rWnGYw/v7dU9bFF\ne0CSR1XVhRlOWX9whmu2bj2eUpX4HGPjrUmyprX2uXH6vRkCoc8vpuEhSb7VWrustXZNkvdn+Ezz\n+cW0resza4v73i8ALoyzkuw2jkC1bYaLkU9a4prYgo3XY/1LkvNaa6+bWHRSkkPG3w9J8h+LXRtb\nvtbaX7fWVrTWdsnwefWJ1tqTkpyW5HFjM8cXG6W1dkmSi6rq18dZv5PkK/H5xXR8J8k+VbXd+G/l\n2uPL5xfTtq7PrJOS/PE4Gug+SX44caroZqmGHkymraoekeGammVJjmutvXKJS2ILVlW/leTMJOfm\nl9do/U2G6wDfk+TOSb6d5AmttZkXLcOcVdWDkjy/tfbIqrprhh7B2yb5QpInt9Z+tpT1sWWqqntl\nGGBo2yTfTHJYhv+E9vnFJquqlyX5gwwjZn8hyZ9luAbL5xcbpapOSPKgJLdLcmmSlyY5MbN8Zo3/\n8fCmDKce/zTJYa211UtR91wJgAAAAJ1wCigAAEAnBEAAAIBOCIAAAACdEAABAAA6IQACAAB0QgAE\nYLNUVX9aVa2qVsyY/+px/pNnzH/oOP/+C1jT6qp620KtfyFU1d2r6siquvVS1wLA0hMAAdhcfXr8\nOTPQ3T/DvZZmm/+zJGcvcF1bmrtnuIeVAAiAAAjAZuurSb6fiaBXVTdNsirJ2zN7ADx7U272XIPl\nG/t8ANjcCYAAbJZaay3JZ3LDoHfv8ec/Jtmjqm6ZJFV1kyT3S/KpyXVU1TOq6utV9bOquqCqnjNj\n+ZFVdXlV/VZVnZXk6iSPH5ftUVWfqqqrq+q8qnrUXGuvqqdU1bnjcy+tqvdW1a0mlj9hXP6zqrqo\nql5ZVdvMrGuW9baqesbE9IVV9dqqek5VramqK6vqXWtP96yqByX5wNj8W+PzL5zr6wBg6yMAArA5\n+3SSe1XVzcfpfTOc4vmlJD/MEPqS5DeS3CoTAbCqnpLk/yQ5KcnvJfm3JH9fVS+csY3tkhyf5C1J\nDkjy+XF7pyTZPskfJvnfSV6f5M4bKriqXpzkmCSfTPLoJH8x1rr9uPxhSd6d5L+SHDTW+Pwkb5rD\n+zGbJyT5nSSHJzkiySOT/O247L/GdSfJ72d4/x6zkdsBYCuwzYab8P/bu3cQuao4juPfv2IkRcQX\nq9E0gpVg49u10EIUsfEBoiCkEiUISrYyCEZXiU0grQRcy9iIwVeMgiJuJphCQVTEZiOrRk1MWHEN\nMeZvcc5kbq4zmV0bh5nvp7l7z7mPM9Xy43/POZKk/808cB5wI/AJpRrYycyMiP31/EN6VcJ9cLoi\nuBV4LTNnat/eWoV7JiJ2ZObx2r4W2JyZu7svjYhNwBRwc2Yu1rYF4NOzDbZW3rYAOzJzc6Prjcbf\nLwAfZ+bGer4nIgC2RcSL3fetwl/AfZl5so7hGuBhYFNmLkXEt/W6zzNzYZXPliSNGSuAkqRRdgA4\nSS/gTVM+CwXY32r/LjN/recbgCsoVb+m14ELgGsbbQm817ruJsp8wtNhLDPngV+GjPdWSqCc69cZ\nEecC1w0Y1zn1/tX6qBv+qq+BqTpfUpKkMxgAJUkjKzOXgS+A6bodxAZ6q4N2gFuilM+mOXP+3/p6\n/Ln1yO75xY22o5l5onXd5fQPe8MC4CX1+NOA/kspFc2VjGuljrXOTwABnP8fniVJGnMGQEnSqJun\nVMamgYXMPFTbPwPWAXcAV9MLhtALYFOtZ11Wj7812rLPOw/1ubff89qO1OP6Af2HKZ9sDhvXcWBN\n84KIuGjIuyVJGsoAKEkadfsolbON9D7/JDOXgK/oLXLSrAAuAj9SV/RseAhYAr4c8s4DwPXNTegj\n4jaGB8AO8Gcd679k5t+URWz6jesUvd+3CKyLiCsb19w15N2DdKubbm8hSXIRGEnSyOtW9u4Bnmr1\ndYDHgKPAN93GzDwVEVuBVyLiCPABcDtlRc4tjQVgBpkDngXeqc9ZC8xSKngDZeaxiJgFXoqINcC7\nlE8x7wWez8wfKJuyvx8Rc8AuynzEWWBnY87hHkqQfDUitgNXAU8MGfMg3UVgHo+IXcByZg4LwJKk\nMWUFUJI00moo+p4yr63T6u502+u+gc37dlIC4/3A28AjwExmvryCdy4DdwN/UELac8AMcHAF926j\nBM07gd2ULSEuBH6v/Xspq3TeQNmj72lgO/Bk4xmHgQcpcx7fBB6lbEexapl5kFIlfYBSJX3r7HdI\nksZZtP5fSpIkSZLGlBVASZIkSZoQBkBJkiRJmhAGQEmSJEmaEAZASZIkSZoQBkBJkiRJmhAGQEmS\nJEmaEAZASZIkSZoQBkBJkiRJmhD/AAlphiQRMHiYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "plt.hist(word_cnt, bins=100, range=[0, 100], color=pal[2], normed=True, label='word_cnt')\n",
    "plt.title('Normalised histogram of word occurence', fontsize=15)\n",
    "plt.legend()\n",
    "plt.xlabel('Word count', fontsize=15)\n",
    "plt.ylabel('Probability', fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# What is the inference of the above plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_trainq1_vec = t.texts_to_sequences(X_trainq1)\n",
    "X_trainq2_vec = t.texts_to_sequences(X_trainq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What does the hammer and sickle represent?\n",
      "[    0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     2    21     1  7350    12\n",
      " 14741  2822]\n"
     ]
    }
   ],
   "source": [
    "# Q2: Why is size of a particular question's text not matching the size of its vector when converted to sequence using texts_to_sequences? \n",
    "print(X_trainq2[78885])\n",
    "print(X_trainq2_vec[3])\n",
    "# Answer to Q2: because trainq2 is a dictonary, 78885 is hash of 3rd index in it. But X_trainq2_vec is a 2D array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "pad_sequences is used to ensure that all sequences in a list have the same length. By default this is done by padding 0 in the beginning of each sequence until each sequence has the same length as the longest sequence.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_trainq1_vec = sequence.pad_sequences(X_trainq1_vec, maxlen=50)\n",
    "X_trainq2_vec = sequence.pad_sequences(X_trainq2_vec, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Q1 shape: (363859, 50)\n",
      "Train Q2 shape: (363859, 50)\n",
      "Train Label shape: (363859,)\n"
     ]
    }
   ],
   "source": [
    "print('Train Q1 shape:', X_trainq1_vec.shape)\n",
    "print('Train Q2 shape:', X_trainq2_vec.shape)\n",
    "print('Train Label shape:', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_validq1_vec = t.texts_to_sequences(X_validq1)\n",
    "X_validq2_vec = t.texts_to_sequences(X_validq2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(X_trainq1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_validq1_vec = sequence.pad_sequences(X_validq1_vec, maxlen=50)\n",
    "X_validq2_vec = sequence.pad_sequences(X_validq2_vec, maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid Q1 shape: (40429, 50)\n",
      "valid Q2 shape: (40429, 50)\n",
      "valid Label shape: (40429,)\n"
     ]
    }
   ],
   "source": [
    "print('valid Q1 shape:', X_validq1_vec.shape)\n",
    "print('valid Q2 shape:', X_validq2_vec.shape)\n",
    "print('valid Label shape:', y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Merge, Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "# fix random seed for reproducibility\n",
    "# np.random.seed(7)\n",
    "\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_sentence_len = 50\n",
    "embedding_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q1_input = Input(shape=(max_sentence_len,), dtype='int32', name='q1_input')\n",
    "q2_input = Input(shape=(max_sentence_len,), dtype='int32', name='q2_input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>\n",
    "Argument input_length: Length of input sequences, when it is constant. This argument is required if you are going to connect Flatten then Dense layers upstream (without it, the shape of the dense outputs cannot be computed).\n",
    "</font>\n",
    "<p>\n",
    "<font color='green'>\n",
    "The output of the Embedding layer is a 2D vector with one embedding for each word in the input sequence of words (input document).\n",
    "\n",
    "If you wish to connect a Dense layer directly to an Embedding layer, you must first flatten the 2D output matrix to a 1D vector using the Flatten layer.\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embed = Embedding(input_dim=25000, output_dim=embedding_dim, input_length=max_sentence_len)\n",
    "embed_q1 = embed(q1_input)\n",
    "embed_q2 = embed(q2_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"embedding_1/GatherV2:0\", shape=(?, 50, 128), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(embed_q1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "<font color='green'>\n",
    "LSTM - Long Short-Term Memory layer \n",
    "</font> </p>\n",
    "<p>\n",
    "<font color='green'>\n",
    "Arguments:\n",
    "units: Positive integer, dimensionality of the output space.\n",
    "\n",
    "\n",
    "</font>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shared_lstm = LSTM(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"lstm_1_2/TensorArrayReadV3:0\", shape=(?, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "encoded_q1 = shared_lstm(embed_q1)\n",
    "encoded_q2 = shared_lstm(embed_q2)\n",
    "print(encoded_q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"transform_mat/Sigmoid:0\", shape=(?, 256), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# transform encoded_q1 to encoded_q2 (inspiration)\n",
    "trans_q1 = Dense(256, activation='sigmoid', name='transform_mat')(encoded_q1)\n",
    "print(trans_q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dot_2/ExpandDims:0\", shape=(?, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# x = keras.layers.dot([encoded_q1, encoded_q2], axes=-1)\n",
    "x = keras.layers.dot([trans_q1, encoded_q2], axes=-1)\n",
    "print(x)\n",
    "# output = keras.layers.activations.sigmoid(x)\n",
    "output = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(inputs=[q1_input, q2_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor 'q1_input_1:0' shape=(?, 50) dtype=int32>, <tf.Tensor 'q2_input_1:0' shape=(?, 50) dtype=int32>]\n",
      "[<tf.Tensor 'dense_1/Sigmoid:0' shape=(?, 1) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "print(model.inputs)\n",
    "print(model.outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "q1_input (InputLayer)           (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 50, 128)      3200000     q1_input[0][0]                   \n",
      "                                                                 q2_input[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "q2_input (InputLayer)           (None, 50)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 256)          394240      embedding_1[0][0]                \n",
      "                                                                 embedding_1[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "transform_mat (Dense)           (None, 256)          65792       lstm_1[2][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1)            0           transform_mat[0][0]              \n",
      "                                                                 lstm_1[3][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            2           dot_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 3,660,034\n",
      "Trainable params: 3,660,034\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tensorboard = TensorBoard(log_dir='./logs/{}'.format(time.strftime('%Y-%m-%dT%H-%M-%S', time.localtime())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 363859 samples, validate on 40429 samples\n",
      "Epoch 1/10\n",
      "363859/363859 [==============================] - 2106s 6ms/step - loss: 0.5605 - acc: 0.7105 - val_loss: 0.5054 - val_acc: 0.7578\n",
      "Epoch 2/10\n",
      "363859/363859 [==============================] - 2071s 6ms/step - loss: 0.4707 - acc: 0.7749 - val_loss: 0.4693 - val_acc: 0.7763\n",
      "Epoch 3/10\n",
      "297984/363859 [=======================>......] - ETA: 15:35 - loss: 0.4254 - acc: 0.8006"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-8d021b5b0883>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_trainq1_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_trainq2_vec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_validq1_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_validq2_vec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtensorboard\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1234\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1236\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1237\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit([X_trainq1_vec, X_trainq2_vec], y_train, validation_data=([X_validq1_vec, X_validq2_vec], y_valid), epochs=10, batch_size=1024, callbacks=[tensorboard])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png')\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
